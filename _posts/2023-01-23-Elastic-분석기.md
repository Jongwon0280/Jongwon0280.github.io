# Elastic ë¶„ì„ê¸°
title: Elastic ë¶„ì„ê¸°
subtitle: 
categories: Elastic
tags: cloud Elastic[D[D[D[D[D[D[D[D[D[D[D[C[C[C[C[C[C[C[C[C[C[C[C[C[C
date: 2023-01-23 23:33:38 +0000
last_modified_at: 2023-01-23 23:33:39 +0000
---

### Setting

ì²˜ìŒ ì¸ë±ìŠ¤ë¥¼ ì •ì˜í•  ë•Œ ìƒ¤ë“œ ìˆ˜ë“±ì„ ì •ì˜í•œë‹¤.

### Mapping

ê° í•„ë“œë³„ë¡œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ìŠ¤í‚¤ë§ˆ ëª…ì„¸, ì¸ë±ìŠ¤, íƒ€ì…ë³„ë¡œ êµ¬ë¶„ëœë‹¤.

ë™ì ë§¤í•‘ì„ ì§€ì›í•œë‹¤.

ìë™ìƒì„±ëœ ë§¤í•‘ì˜ í…ìŠ¤íŠ¸ í•„ë“œëŠ” ê¹ê³¤ì ìœ¼ë¡œ ìŠ¤íƒ ë‹¤ë“œ ì• ë„ë¼ì´ì €ì´ë‹¤.

### Data Type

ë¬¸ìì—´ â†’ text, keyword

ì§€ë¦¬ì •ë³´ â†’ geo_point, geo_shape (í‚¤ë°”ë‚˜ ì§€ë„ì—ì„œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.)

**text â†’ ì…ë ¥ëœ ë¬¸ìë¥¼ í…€ ë‹¨ìœ„ë¡œ ìª¼ê°œì–´ ì—­ ìƒ‰ì¸ êµ¬ì¡°ë¥¼ ë§Œë“ ë‹¤.**

**ë³´í†µ í’€ í…ìŠ¤íŠ¸ ê²€ìƒ‰ì— ì‚¬ìš©í•  ë¬¸ìì—´ í•„ë“œë“¤ì„ textíƒ€ì…ìœ¼ë¡œ ì§€ì •í•œë‹¤.**

**tokenâ†’ í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ì €ì¥í•œë‹¤.**

********object â†’ JSONí˜•íƒœë¡œ ì´ë£¨ì–´ì ¸ìˆê¸° ë•Œë¬¸ì— ì—¬ëŸ¬í•„ë“œë¥¼ ê°€ì§„ object íƒ€ì…ì˜ í•„ë“œë¥¼ ë§Œë“¤ ìˆ˜ ìˆë‹¤.********

â‡’ propertiesì•„ë˜ì— í•˜ìœ„ í•„ë“œ ì´ë¦„ê³¼ íƒ€ì…ì„ ì§€ì •í•œë‹¤.

ë‹¨ì  : **object type**ì€ í•˜ìœ„í•„ë“œ ì¡°íšŒí• ë•Œ ëª¨ë“  ìƒìœ„ í•„ë“œê°€ ì¡°íšŒëœë‹¤.

**Nested â†’ properties: characters : type = nested**

### Text Analysis

í…ìŠ¤íŠ¸ ë¶„ì„ì€ Analyzerë¼ê³  í•˜ëŠ” ë„êµ¬ê°€ ìˆ˜í–‰ëœë‹¤.

<aside>
ğŸ‘‰ **ìºë¦­í„° í•„í„°ë§(ìµœëŒ€3ê°œ)** â†’ **í† í¬ë‚˜ì´ì €** â†’ **í† í°í•„í„°**

</aside>

 

- ìºë¦­í„°í•„í„°ë‚˜ í† í°í•„í„°ëŠ” ìˆœì„œê°€ ì¤‘ìš”í•˜ë‹¤
- Pattern Replace / Mapping / HTML Strip

### _analyze API

ë¶„ì„ëœ ë¬¸ì¥ì„ apië¥¼ ì´ìš©í•´ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

í•„í„°ëŠ” []ì•ˆì— ë°°ì—´ í˜•íƒœë¡œ ì €ì¥í•œë‹¤.

```json
GET _analyze
{
  "text": "The quick brown fox jumps over the lazy dog",
  "tokenizer": "whitespace",
  "filter": [
    "lowercase",
    "stop",
    "snowball"
  ]
}
```

- **Character Filter**
    
    ì „ì²´ë°ì´í„°ì— ì ìš©ë˜ëŠ” ì¼ì¢…ì˜ ì „ì²˜ë¦¬ ë„êµ¬ì´ë‹¤.
    
    - Pattern Replace / Mapping / HTML Strip
- **HTML Strip**
    
    ì…ë ¥ëœ í…ìŠ¤íŠ¸ê°€ HTMLì¸ ê²½ìš° íƒœê·¸ë¥¼ ì‚­ì œí•˜ì—¬ ì¼ë°˜í…ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì¤€ë‹¤.
    
- **Mapping**
    
    ì§€ì •í•œ ë‹¨ì–´ë¥¼ ë‹¤ë¥¸ì–¸ì–´ë¡œ ì¹˜í™˜ì´ ê°€ëŠ¥í•˜ë‹¤.
    
    - **+ë¥¼  _plus_ë¡œ ì¹˜í™˜í•˜ëŠ” mapping ìºë¦­í„° í•„í„° ì˜ˆì œ**

```json
PUT coding
{
  "settings": {
    "analysis": {
      "analyzer": {
        "coding_analyzer": {
          "char_filter": [
            "cpp_char_filter"
          ],
          "tokenizer": "whitespace",
          "filter": [ "lowercase", "stop", "snowball" ]
        }
      },
      "char_filter": {
        "cpp_char_filter": {
          "type": "mapping",
          "mappings": [ "+ => _plus_", "- => _minus_" ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "language": {
        "type": "text",
        "analyzer": "coding_analyzer"
      }
    }
  }
}
```

**+Pattern_replace**

- **Tokenizer**
    
    ```json
    GET _analyze
    {
      "text" : "abc# !@ fox emwte",
      "tokenizer": "standard" // whitespace letter
    }
    ```
    

- **Token Filter**
    
    ë¶„ë¦¬ëœ ê°ê°ì˜ í…€ë“¤ì„ ì§€ì •í•œ ê·œì¹™ì— ë”°ë¼ ì²˜ë¦¬ í•´ì£¼ëŠ” ê³¼ì •ì„ ë‹´ë‹¹í•œë‹¤.
    
    ë°°ì—´ì•ˆì˜ ìˆœì„œë¥¼ ê³ ë ¤í•´ì•¼í•œë‹¤.
    
    ì¢…ë¥˜ : **lowercase, uppercase, stop, synonym, ngram**
    
    - **Lowercase, Uppercase**
        
        ëŒ€ì†Œë¬¸ìê°€ ìƒê´€ì—†ì´ ê²€ìƒ‰ì´ ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜ì‹œì¼œì£¼ëŠ” í•„í„°ì´ë‹¤.
        
        ```json
        GET _analyze
        {
          "filter" : ["lowercase"], // uppercase
          "text": "HIEVERYONE"
        }
        ```
        
    - **Stop**
        
        ë¶ˆìš©ì–´ë¥¼ ì œê±°í•´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. ì˜ˆì‹œì—ì„œëŠ” in / the / days ìˆœì´ë‹¤.
        
        ```json
        //í•„í„°ìƒì„±
        PUT my_stop
        {
          "settings": {
            "analysis": {
              "filter": {
                "my_stop_filter": {
                  "type": "stop",
                  "stopwords": [
                    "a",
                    "at",
                    "will"
                  ]
                }
              }
            }
          }
        }
        //ë¶„ì„ê¸°ì— í•„í„°ì ìš©í•¨.
        GET my_stop/_analyze
        {
          "tokenizer": "whitespace",
          "filter": [
            "lowercase",
            "my_stop_filter"
          ],
          "text": [ "Around the World in Eighty Days" ]
        }
        
        ```
        
        <aside>
        ğŸ‘‰ **ì‹¤í–‰ê²°ê³¼** : "token": "around", "token": "world","token": "eighty"
        
        </aside>
        
        - ë¶ˆìš©ì–´ì‚¬ì „ì„ stopword_pathë¥¼ í†µí•´ ë¶ˆìš©ì–´ ì‚¬ì „ì˜ ê²½ë¡œë¥¼ ì§€ì •í•´ì¤€ë‹¤.
        
    - **Synonym**
        
        ë™ì˜ì–´ë¥¼ ì§€ì •í•˜ëŠ” í•„í„°ì´ë‹¤.
        
        â€œsynonymsâ€ : []  í•­ëª© ì•ˆì— ë°°ì—´ë¡œ ì €ì¥í•œë‹¤.
        
        ex) synonyms : [â€A,B â‡’ Câ€] : ì™¼ìª½ì˜ A,B ëŒ€ì‹  Cí…€ì„ ì €ì¥í•œë‹¤.
        
        ```json
        PUT my_synonym
        {
          "settings": {
            "analysis": {
              "analyzer": {
                "my_syn": {
                  "tokenizer": "whitespace",
                  "filter": [
                    "lowercase",
                    "syn_aws"
                  ]
                }
              },
              "filter": {
                "syn_aws": {
                  "type": "synonym",
                  "synonyms": [
                    "amazon, aws"
                  ]
                }
              }
            }
          },
          "mappings": {
            "properties": {
              "message": {
                "type": "text",
                "analyzer": "my_syn"
              }
            }
          }
        }
        
        PUT my_synonym/_doc/1
        { "message" : "Amazon Web Service" }
        PUT my_synonym/_doc/2
        { "message" : "AWS" }
        
        GET my_synonym/_search
        {
          "query" : {
            "match" : {
              "message" : "aws"
            }
          }
        }
        
        ```
        
    
    - **ngram**
        
        ê²€ìƒ‰ í…€ì˜ ì¼ë¶€ë§Œ ë¯¸ë¦¬ ë¶„ë¦¬í•´ì„œ ì €ì¥ì„ í•  ìˆ˜ ìˆëŠ”ë° ì´ë ‡ê²Œ ë‹¨ì–´ë¥¼ ë‚˜ëˆˆ ë¶€ìœ„ë¥¼ ngramì´ë¼ê³ í•œë‹¤. â†’ ë©”ë‰´ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì‘ì„±í•´ì¤„ë•Œ **(ìë™ì™„ì„±ê¸°ëŠ¥ì„ êµ¬í˜„í•  ë•Œ ì‚¬ìš©í•œë‹¤.)**
        
        - **min_gram(default 1), max_gram(default 2)**
        - **max_ngram_diffìœ¼ë¡œ minê³¼ maxì‚¬ì´ì˜ ê°’ì„ ì¡°ì •í•  ìˆ˜ ìˆë‹¤.**
        
        ```json
        PUT my_ngram
        {
        	"settings" : {
        		"analysis" : {
        			"filter" : {
        				"my_ngram" : {
        					"type" : "ngram",
        					"min_gram" : 2,
        					"max_gram" : 3
        				}
        			}
        		}
        	}
        }
        
        GET my_ngram/_analyze
        {
        	"tokenizer" : "keyword",
        	"filter" : ["my_ngram"],
        	"text" : "house"
        }
        ```
        
        <aside>
        ğŸ‘‰ **ê²°ê³¼ : ho hou ou ous â€¦. use**
        
        </aside>
        
    
    - **Edge Ngram**
        
        ì•ìª½ì˜ ngramë§Œì„ ì €ì¥í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•œë‹¤.
        
        ex) (min:1 max:4) **house** = h , ho, hou, hous
        
    - **Shingle**
        
        ë‹¨ì–´ ë‹¨ìœ„ë¡œ êµ¬ì„±ëœ ë¬¶ìŒìœ¼ë¡œ ë¶„ë¦¬ í•  ë•Œ ì‚¬ìš©í•œë‹¤.
        
        ex) **This is my sweet home** = this is , is my, my sweet, sweet home
        

### Simple Analyzer

ë‹¨ì–´ê°€ ì•„ë‹Œ ë¬¸ìë¡œ í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  ë¬¸ìê°€ ì•„ë‹Œ ë¬¸ìë¥¼ ì œê±°.

### Whitespace Analyzer

ê³µë°±ë¬¸ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìë¥´ëŠ” analyzer

### Stop Analyzer

ë¶ˆìš©ì–´ë¥¼ ì œê±°í•˜ê¸° ìœ„í•œ í•„í„°ê°€ ì¶”ê°€ë˜ì–´ìˆìŒ.

### Keyword Analyzer

ë¬¸ìì—´ ì „ì²´ë¥¼ í† í°ìœ¼ë¡œ ì·¨ê¸‰

### Custom Analyzer

customí† í¬ë‚˜ì´ì €, customí† í°í•„í„°ë“±ì„ ì¡°í•©í•˜ì—¬ ë§Œë“¤ ìˆ˜ ìˆë‹¤.

ì¸ë±ìŠ¤ì˜ settingsì˜ index : { â€œanalysisâ€ : 

1. **ì‚¬ìš©í•  í† í¬ë‚˜ì´ì € ì§€ì •.**
2. **í† í¬ë‚˜ì´ì €ì— í•´ë‹¹í•˜ëŠ” ì˜µì…˜ì„ ì§€ì •**
3. **ì‚¬ìš©í•  í† í° í•„í„°ë¥¼ ì •ì˜**
4. **í† í° í•„í„°ì— ëŒ€í•œ ì˜µì…˜ì„ ì§€ì •**
5. **ì• ë„ë¼ì´ì €ì˜ ëª…ì„ ì •í•˜ê³  ì‚¬ìš©í•œ í† í°ë‚˜ì´ì €ì™€ í† í°í•„í„°ë¥¼ ì‘ì„±**
6. **mappingsì˜ í•„ë“œì— ì •ì˜í•´ì¤€ ì• ë„ë¼ì´ì €ì˜ ëª…ì„ ì§€ì •í•´ì¤€ë‹¤.**

### nori(í•œê¸€ë¶„ì„ê¸°)

ì• ë„ë¼ì´ì € : nori

í† í¬ë‚˜ì´ì € : nori_tokenizer

í† í°í•„í„° : nori_part_of_speech, nori_readingform, nori_number

- **nori_tokenizer**
    
    **user_dictionary_rules, user_dictionary**
    
    â€œë™í•´ë¬¼ê³¼ ë°±ë‘ì‚°ì´â€ â†’ â€œë™í•´â€ â€œë¬¼â€ â€¦.
    
    **user_dictionary_rules** : ì‚¬ìš©ì ì •ì˜ì‚¬ì „ì„ ë°°ì—´ë¡œ ì…ë ¥í•©ë‹ˆë‹¤.
    
    **nori_part_of_speech** : ì¡°ì‚¬ í˜•ìš©ì‚¬ë¥¼ ì œê±°í•˜ëŠ” ê²ƒ
    
    ```json
    PUT my_pos
    {
      "settings": {
        "analysis": {
          "filter": {
            "my_pos_f": {
              "type": "nori_part_of_speech",
              "stoptags": [
                "NR", "J"
              ]
            }
          }
        }
      }
    }
    ```
    
    ```json
    GET my_pos/_analyze
    {
      "tokenizer": "nori_tokenizer",
      "filter": [
        "my_pos_f"
      ],
      "text": "ë‹¤ì„¯ì•„ì´ê°€"
    }
    //ìˆ˜ì‚¬ì¸ ë‹¤ì„¯ì´ë‘ 'ê°€'ì œê±°ëœë‹¤.
    ```
    
- **nori_readingform**
    
    í•œìë¥¼ í•œê¸€ë¡œ ë³€í™˜í•´ì£¼ëŠ” í•„í„°ì´ë‹¤.
    
- **nori_number**
    
    í•œê¸€ ìˆ«ìë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì£¼ëŠ” í•„í„°ì´ë‹¤.
    

- day3

[AWS / Elastic Day3](https://www.notion.so/AWS-Elastic-Day3-d634a33f9dfe4128befe69d14c68e838)